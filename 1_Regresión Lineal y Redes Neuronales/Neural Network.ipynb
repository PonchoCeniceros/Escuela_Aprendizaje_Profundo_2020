{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# X = (hours studying, hours sleeping), y = score on test\n",
    "\n",
    "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float) # 3 X 2 tensor\n",
    "y = torch.tensor(([92], [100], [89]), dtype=torch.float) # 3 X 1 tensor\n",
    "xPredicted = torch.tensor(([4, 8]), dtype=torch.float) # 1 X 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale units\n",
    "X_max, _ = torch.max(X, 0)\n",
    "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
    "\n",
    "X = torch.div(X, X_max)\n",
    "xPredicted = torch.div(xPredicted, xPredicted_max)\n",
    "y = y / 100  # max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6667, 1.0000],\n",
      "        [0.3333, 0.5556],\n",
      "        [1.0000, 0.6667]])\n",
      "tensor([[0.9200],\n",
      "        [1.0000],\n",
      "        [0.8900]])\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\NN_img.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        # parameters\n",
    "        # TODO: parameters can be parameterized instead of declaring them here\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "        # weights\n",
    "        self.W1 = torch.randn(self.inputSize, self.hiddenSize) # 2 X 3 tensor\n",
    "        self.W2 = torch.randn(self.hiddenSize, self.outputSize) # 3 X 1 tensor\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z = torch.matmul(X, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
    "        self.z2 = self.sigmoid(self.z) # activation function\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) # final activation function\n",
    "        return o\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        # derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, \"NN\")\n",
    "        # you can reload model with all the weights and so forth with:\n",
    "        # torch.load(\"NN\")\n",
    "        \n",
    "    def predict(self):\n",
    "        print (\"Predicted data based on trained weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
    "        print (\"Output: \\n\" + str(self.forward(xPredicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.6067922115325928\n",
      "#1 Loss: 0.5414047837257385\n",
      "#2 Loss: 0.4670482873916626\n",
      "#3 Loss: 0.38978829979896545\n",
      "#4 Loss: 0.3166760504245758\n",
      "#5 Loss: 0.2526865303516388\n",
      "#6 Loss: 0.1996547430753708\n",
      "#7 Loss: 0.15720289945602417\n",
      "#8 Loss: 0.12396380305290222\n",
      "#9 Loss: 0.09830711036920547\n",
      "#10 Loss: 0.07866452634334564\n",
      "#11 Loss: 0.06366608291864395\n",
      "#12 Loss: 0.05218810960650444\n",
      "#13 Loss: 0.04335048794746399\n",
      "#14 Loss: 0.036485716700553894\n",
      "#15 Loss: 0.03109767846763134\n",
      "#16 Loss: 0.026821285486221313\n",
      "#17 Loss: 0.023388618603348732\n",
      "#18 Loss: 0.020602596923708916\n",
      "#19 Loss: 0.018317393958568573\n",
      "#20 Loss: 0.016424192115664482\n",
      "#21 Loss: 0.014841065742075443\n",
      "#22 Loss: 0.013505734503269196\n",
      "#23 Loss: 0.01237032562494278\n",
      "#24 Loss: 0.01139774452894926\n",
      "#25 Loss: 0.010558885522186756\n",
      "#26 Loss: 0.009830796159803867\n",
      "#27 Loss: 0.009195112623274326\n",
      "#28 Loss: 0.008637096732854843\n",
      "#29 Loss: 0.008144794963300228\n",
      "#30 Loss: 0.007708411663770676\n",
      "#31 Loss: 0.0073199342004954815\n",
      "#32 Loss: 0.006972679402679205\n",
      "#33 Loss: 0.006661105901002884\n",
      "#34 Loss: 0.0063805473037064075\n",
      "#35 Loss: 0.006127078086137772\n",
      "#36 Loss: 0.005897379945963621\n",
      "#37 Loss: 0.00568860350176692\n",
      "#38 Loss: 0.005498325917869806\n",
      "#39 Loss: 0.005324451718479395\n",
      "#40 Loss: 0.005165173206478357\n",
      "#41 Loss: 0.005018936935812235\n",
      "#42 Loss: 0.004884377587586641\n",
      "#43 Loss: 0.004760297946631908\n",
      "#44 Loss: 0.004645652137696743\n",
      "#45 Loss: 0.004539533983916044\n",
      "#46 Loss: 0.004441122058779001\n",
      "#47 Loss: 0.004349714610725641\n",
      "#48 Loss: 0.004264665301889181\n",
      "#49 Loss: 0.004185400903224945\n",
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "tensor([0.5000, 1.0000])\n",
      "Output: \n",
      "tensor([0.9133])\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(50):  # trains the NN \n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
